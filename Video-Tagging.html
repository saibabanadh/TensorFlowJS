
<html>
	<head>
		<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
		<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet"> </script>

	</head>

	<body>
		<video width=640 height=480 autoplay muted loop playsinline id="movie">
			<source src="wild-life.mp4" type="video/mp4" />
		</video>

		<canvas width=640 height=480 id="output">

		<script>

			// process video
			async function video_tagging()
			{

				// get video stream
				const stream = document.getElementById("movie");

				// load and prepare HTML canvas
				const canvas = document.getElementById("output");
				var draw = canvas.getContext("2d");
				draw.font = "20px Arial";
				draw.fillStyle = "yellow";

				// load the mobile-net model
				const model = await mobilenet.load();

				while(1)
				{

					// fill canvas object with video stream
					draw.drawImage(stream, 0, 0, canvas.width, canvas.height);

					// running image classification
					const result = await model.classify(canvas);

					// get class label
					const class_label = result[0].className;

					const tags = class_label.split(", ");
					common_name = tags[0].toLowerCase();
					species = tags[tags.length - 1].toLowerCase();

					const label = common_name.concat(" ( ", species, " ) ");
					// print label on screen
					draw.fillText(label, 100, 50);

					await tf.nextFrame();
				}

			}

			// check if the video is ready for processing
			function main()
			{
				video = document.getElementById("movie");
				if(video.readyState == 4)
				{
					console.log("video is ready for processing..");
					video_tagging();
				}
				else
				{
					console.log("nope, not ready yet..");
					setTimeout(main, 1000/30);
				}
			}

			main();
		</script>
	</body>
</html>
